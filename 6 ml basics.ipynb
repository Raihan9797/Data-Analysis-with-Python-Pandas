{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will be predicting the price of diamonds based on their features (carat, cut color clarity etc)\n",
    "\n",
    "### put all these features into a regression model using sci kit learn!\n",
    "\n",
    "### for ML you need >10 000 Deep Learning >100 000.\n",
    "\n",
    "### sklearn cheatsheet for choosing the right estimator!: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "### in our case of 50k rows, we are looking for qty so we should be using SVR (which is basically svm for REGRESSION and also using the LINEAR kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   carat      cut color clarity  depth  table  price     x     y     z\n1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>price</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.23</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>61.5</td>\n      <td>55.0</td>\n      <td>326</td>\n      <td>3.95</td>\n      <td>3.98</td>\n      <td>2.43</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.21</td>\n      <td>Premium</td>\n      <td>E</td>\n      <td>SI1</td>\n      <td>59.8</td>\n      <td>61.0</td>\n      <td>326</td>\n      <td>3.89</td>\n      <td>3.84</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.23</td>\n      <td>Good</td>\n      <td>E</td>\n      <td>VS1</td>\n      <td>56.9</td>\n      <td>65.0</td>\n      <td>327</td>\n      <td>4.05</td>\n      <td>4.07</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.29</td>\n      <td>Premium</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.4</td>\n      <td>58.0</td>\n      <td>334</td>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>2.63</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.31</td>\n      <td>Good</td>\n      <td>J</td>\n      <td>SI2</td>\n      <td>63.3</td>\n      <td>58.0</td>\n      <td>335</td>\n      <td>4.34</td>\n      <td>4.35</td>\n      <td>2.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"D:\\d Documents\\datasets for practice\\diamonds.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## things to take note in ML: it's easy to cheat, even when you are trying not to!\n",
    "\n",
    "### in any case, we need to convert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Ideal', 'Premium', 'Good', 'Very Good', 'Fair'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df['cut'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as you can see, it seems that the 'cut' is in categories and that they can be ordered ie \"fair\" is better than \"Good\". \n",
    "\n",
    "### we could just convert it to categorical using the code below, but this assigns levels based on which it sees first, which is not very good if we are trying to do linear regression (higher cut, should have higher price ie positive coeff)\n",
    "\n",
    "### lets create a dict instead which links the names to incresing values. WE GET THE ADDITIONAL DATA BY LOOKING AT KAGGLE eg clarity of i3 : 1 and i2: 2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['cut'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   carat  cut  color  clarity  depth  table  price     x     y     z\n1   0.23    5      6        4   61.5   55.0    326  3.95  3.98  2.43\n2   0.21    4      6        5   59.8   61.0    326  3.89  3.84  2.31\n3   0.23    2      6        7   56.9   65.0    327  4.05  4.07  2.31\n4   0.29    4      2        6   62.4   58.0    334  4.20  4.23  2.63\n5   0.31    2      1        4   63.3   58.0    335  4.34  4.35  2.75",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>price</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.23</td>\n      <td>5</td>\n      <td>6</td>\n      <td>4</td>\n      <td>61.5</td>\n      <td>55.0</td>\n      <td>326</td>\n      <td>3.95</td>\n      <td>3.98</td>\n      <td>2.43</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.21</td>\n      <td>4</td>\n      <td>6</td>\n      <td>5</td>\n      <td>59.8</td>\n      <td>61.0</td>\n      <td>326</td>\n      <td>3.89</td>\n      <td>3.84</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.23</td>\n      <td>2</td>\n      <td>6</td>\n      <td>7</td>\n      <td>56.9</td>\n      <td>65.0</td>\n      <td>327</td>\n      <td>4.05</td>\n      <td>4.07</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.29</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>62.4</td>\n      <td>58.0</td>\n      <td>334</td>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>2.63</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.31</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>63.3</td>\n      <td>58.0</td>\n      <td>335</td>\n      <td>4.34</td>\n      <td>4.35</td>\n      <td>2.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cut_class_dict = {\"Fair\": 1, \"Good\": 2, \"Very Good\": 3, \"Premium\": 4, \"Ideal\": 5}\n",
    "\n",
    "clarity_dict = {\"I3\": 1, \"I2\": 2, \"I1\": 3, \"SI2\": 4, \"SI1\": 5, \"VS2\": 6, \"VS1\": 7, \"VVS2\": 8, \"VVS1\": 9, \"IF\": 10, \"FL\": 11}\n",
    "\n",
    "color_dict = {\"J\": 1,\"I\": 2,\"H\": 3,\"G\": 4,\"F\": 5,\"E\": 6,\"D\": 7}\n",
    "\n",
    "## ONLY RUN THIS ONCE! COPY() DOES NOT SEEM TO SAVE THIS. MOST LIKELY DUE TO MAP()\n",
    "df['cut'] = df['cut'].copy().map(cut_class_dict)\n",
    "df['clarity'] = df.copy()['clarity'].copy().map(clarity_dict)\n",
    "df['color'] = df.copy()['color'].map(color_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALWAYS START BY SHUFFLING THE DATA. It might be ordered even if you don't think it is. In this case, it does appear that this data set is sorted by price\n",
    "\n",
    "### also imagine if you did not set the column when you took in the diamonds.csv! this would mean that the numbered index actually correl to price because 1 is the first row which is kinda the highest few prices! watch out for that.\n",
    "\n",
    "### basically this would inform the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sklearn.utils.shuffle(df)\n",
    "\n",
    "x = df.drop(\"price\", axis = 1).values\n",
    "y = df['price'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's also scale the x vals using preprocessing. So instead of the cuts having values from 1 to 5, the range is scaled down to 0 to 1.\n",
    "\n",
    "### this simplifies the model ie reduce its complexity. you can comment out the preprocessing to see if it actually makes a huge difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.scale(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separating into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n    tol=0.001, verbose=False)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "test_size = 200\n",
    "\n",
    "x_train = x[:-test_size] #all the way up to the last 200\n",
    "y_train = y[:-test_size]\n",
    "\n",
    "x_test = x[-test_size:] # the last 200\n",
    "y_test = y[-test_size:]\n",
    "\n",
    "clf = svm.SVR(kernel=\"linear\")\n",
    "clf.fit(x_train, y_train) # training ie fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8655622526391615"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "clf.score(x_test, y_test) # 0 bad 1 is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification is much more clear cut than regression, whether it's in the correct class or not. regression is abit more vague. let's try and look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(751.9170683611669, 1069),\n (-254.52774027894156, 477),\n (1934.2725126734936, 1728),\n (5490.475624454063, 7035),\n (3112.005133033288, 2422),\n (5330.47444654415, 6425),\n (546.2661289376388, 645),\n (852.7532708098515, 1080),\n (979.8292868542112, 1399),\n (4238.207338622738, 3080),\n (6036.502669136721, 7038),\n (887.2620781525402, 1087),\n (182.00209785769948, 834),\n (1643.5989046183959, 1243),\n (703.9532361224301, 678),\n (1519.880361364359, 1148),\n (5760.631929781412, 6232),\n (1006.7936384752998, 998),\n (1666.2286179953453, 1152),\n (6201.178746330784, 3788),\n (3522.373658809984, 3209),\n (4053.4472471632466, 3282),\n (1048.880689557986, 990),\n (224.54333453283562, 802),\n (2132.792109875146, 2064),\n (1156.8371413376885, 1076),\n (5253.480023538255, 6645),\n (2470.8165092097634, 2039),\n (5102.931378092467, 7135),\n (26.816401289768237, 507),\n (2044.5888321823084, 1763),\n (1515.9381501792673, 1417),\n (9075.57540459666, 12028),\n (3309.0787341603373, 3077),\n (32.77586966260333, 579),\n (2859.3482449589756, 2400),\n (1597.2168148078204, 1289),\n (1636.8883961153458, 1264),\n (1180.6443177219812, 1028),\n (2039.8117271945614, 1919),\n (3232.0653681673857, 2452),\n (-203.49575859124798, 469),\n (4722.461112376681, 5034),\n (4663.986608931854, 4462),\n (4104.872212848777, 3998),\n (1637.1591114356688, 1243),\n (2631.6922933649184, 2010),\n (7653.056157012371, 7957),\n (-151.16727531336892, 628),\n (2085.9916828721043, 1754),\n (6472.4689844949335, 4045),\n (926.4742591152726, 998),\n (4436.312601337034, 3713),\n (39.588418513688794, 684),\n (4033.14615898983, 3701),\n (-228.8553182846549, 473),\n (2993.9242451836662, 2657),\n (5437.53675645423, 7665),\n (4999.33016386318, 5215),\n (6718.054502619194, 7079),\n (12125.1370460824, 18115),\n (2909.98944747869, 2724),\n (2134.414887646466, 1811),\n (5997.176317322779, 5822),\n (437.75146974573863, 923),\n (984.9236964651145, 956),\n (764.2372318440225, 923),\n (3421.8704984587966, 3309),\n (1229.1750388212095, 918),\n (1044.1024408152557, 1023),\n (916.9264744290349, 772),\n (821.4248593517732, 781),\n (762.3631544960531, 1033),\n (959.1008238498798, 1240),\n (1431.3578530457535, 1287),\n (4611.904357644467, 4836),\n (6824.699019280173, 9820),\n (8702.223497310773, 10224),\n (203.46039500808956, 625),\n (8920.905998160768, 7943),\n (2368.9492869139676, 2018),\n (904.666447333088, 928),\n (2789.471233861797, 2012),\n (4729.2390446946665, 4238),\n (-169.76056867596435, 493),\n (8825.147671450903, 11846),\n (17273.770091983846, 17146),\n (290.13915845890097, 571),\n (5967.175178838809, 5502),\n (3362.7787494649388, 3342),\n (13817.710353339982, 15323),\n (-417.4915807766906, 394),\n (25831.79462347819, 15984),\n (3810.9683251949546, 3033),\n (9543.294181097437, 14624),\n (3470.479271633472, 2846),\n (3152.1294797570336, 2573),\n (477.2249210495497, 702),\n (1167.6934484156504, 914),\n (3585.851165757047, 3093),\n (3500.807871990907, 3354),\n (419.9718480367169, 906),\n (1245.7961772486933, 886),\n (221.9596996515893, 548),\n (8678.636683444465, 12571),\n (278.43886486762676, 686),\n (5087.991352912183, 4733),\n (375.91640896946774, 715),\n (7642.974089491821, 11584),\n (3538.3940453558175, 3060),\n (630.2117356226131, 1013),\n (3548.104473309341, 3387),\n (2632.5351162635884, 2241),\n (2878.8740458189545, 2686),\n (3793.9528499515222, 3593),\n (5119.645902359327, 5988),\n (14306.529441387782, 16021),\n (3211.7444725917053, 2607),\n (3939.055429723292, 3084),\n (4496.77168841229, 4225),\n (3942.9938691270563, 3462),\n (882.6439932101912, 803),\n (498.57029587095667, 485),\n (8343.681948574476, 8014),\n (3555.3183647519877, 3356),\n (265.4402475053271, 589),\n (1863.9175758191627, 1440),\n (1816.5595598294333, 1574),\n (11793.195390425471, 13320),\n (2279.7273702826624, 1984),\n (7307.885845999726, 13257),\n (286.126662955905, 732),\n (1976.631353910689, 1608),\n (5695.56699540843, 6168),\n (-553.8911384014709, 432),\n (1011.2264982146608, 1042),\n (366.53188817734963, 802),\n (874.9825171370326, 810),\n (7123.090161845759, 9802),\n (373.18772195132306, 771),\n (4751.379289686627, 4525),\n (-243.16296034792458, 477),\n (8525.80033875982, 9640),\n (528.4904861371087, 633),\n (4640.861829726493, 4771),\n (6253.08705985069, 6189),\n (2136.6393182100355, 1879),\n (4432.6572685271785, 5431),\n (12217.092376400567, 15335),\n (-243.09505822819438, 455),\n (111.9213140136385, 552),\n (5719.517270147469, 5376),\n (2922.593306458475, 2677),\n (8846.136016339751, 11760),\n (1313.7762528153316, 1168),\n (3012.8212639074864, 2504),\n (5488.013011654643, 5035),\n (2894.0669547759253, 2513),\n (5312.854873820582, 3918),\n (2522.7158232126167, 2131),\n (1906.532302873973, 1446),\n (887.8901162563825, 863),\n (-299.54066701408556, 558),\n (-317.25043436730084, 457),\n (7209.761515842291, 9333),\n (3793.7571461765506, 2753),\n (336.82109842226646, 533),\n (1449.587991041055, 1333),\n (3330.2399450848225, 3087),\n (324.13605282933486, 575),\n (6856.15483341425, 9025),\n (3483.7184247591063, 3014),\n (10840.872457939091, 17729),\n (1245.0364259535472, 1076),\n (4761.020474069724, 3945),\n (4018.8041012932035, 3192),\n (2537.552409304235, 2041),\n (4471.908820739659, 4898),\n (-576.8213426952025, 395),\n (3113.588633272836, 2780),\n (823.2205424617691, 1041),\n (326.9611801158726, 645),\n (146.7038248445051, 645),\n (4536.743575304174, 4179),\n (234.995623218555, 625),\n (2483.186118731203, 2558),\n (8129.904926979395, 8574),\n (3738.319922124218, 3511),\n (749.8731854316075, 720),\n (2973.215930684152, 2853),\n (5817.708566999194, 5712),\n (725.5556248146481, 1035),\n (4373.395512948763, 4759),\n (1688.8309684372316, 1345),\n (367.71476772237975, 596),\n (229.28478635615375, 581),\n (2409.6598513538092, 2454),\n (12359.308454305667, 16386),\n (2738.0120801633016, 2384),\n (4921.092409840816, 5499)]"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "#for x, y in zip(x_test, y_test):\n",
    " #   print(clf.predict[x][0], y)\n",
    "\n",
    "list(zip(clf.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are in the general ballpark, but some of them are weird eg this model wants you to pay people to get the diamond off you (-254, 477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVR(kernel=\"rbf\")\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_test) # 0 bad 1 is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(clf.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generally for ML, we use an ensemble of classifiers (ie alot of classifiers) and they will all make predictions to which you will determine an avg prediction. Also, if they give wrong numbers ie negative, we throw that classifier out\n",
    "\n",
    "### we can even make a voting classifier in sklear to improve the Rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python35464bit846037f6322143c096c385b3f70ce6e5",
   "display_name": "Python 3.5.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}